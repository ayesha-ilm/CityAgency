{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0430331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from time import sleep\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44643b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAVE_API_KEY = os.getenv(\"BRAVE_API_KEY\")\n",
    "MAX_QUERIES = os.getenv(\"MAX_QUERY_COUNT\")\n",
    "query_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d61450a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def extract_links(city, state):\n",
    "    global query_count\n",
    "    result = {\n",
    "        \"city\": city,\n",
    "        \"state\": state,\n",
    "        \"official_site\": \"NOT_FOUND\",\n",
    "        \"utility_sites\": []\n",
    "    }\n",
    "    if query_count >= MAX_QUERIES:\n",
    "        print(\"Reached Brave API limit. Stopping...\")\n",
    "        raise StopIteration\n",
    "\n",
    "    # --- OFFICIAL SITE ---\n",
    "    official_query = f\"{city} {state} official city site\"\n",
    "    official_links = brave_search(official_query)\n",
    "    sleep(random.uniform(1.2, 1.6))\n",
    "\n",
    "    if official_links:\n",
    "        result[\"official_site\"] = official_links[0]\n",
    "\n",
    "    for link in official_links:\n",
    "        if \"wikipedia.org\" in link.lower():\n",
    "            continue \n",
    "        if \"facebook.com\" in link.lower():\n",
    "            continue \n",
    "        result[\"official_site\"] = link\n",
    "        break\n",
    "    if query_count >= MAX_QUERIES:\n",
    "        print(\"Reached Brave API limit. Stopping...\")\n",
    "        raise StopIteration\n",
    "    \n",
    "    print(\"query count: \", query_count)\n",
    "\n",
    "    # --- UTILITY SITES ---\n",
    "    utility_query = f\"{city} {state} pay utility water sewer electric bill site\"\n",
    "    utility_links = brave_search(utility_query, num=15)\n",
    "    sleep(random.uniform(1.2, 1.6))\n",
    "\n",
    "    if utility_links:\n",
    "        seen_domains = set()\n",
    "        cleaned = []\n",
    "        for link in utility_links:\n",
    "            domain = urlparse(link).netloc\n",
    "            if domain not in seen_domains:\n",
    "                cleaned.append(link)\n",
    "                seen_domains.add(domain)\n",
    "            if len(cleaned) == 5:\n",
    "                break\n",
    "        result[\"utility_sites\"] = cleaned\n",
    "    else:\n",
    "        result[\"utility_sites\"] = [\"NOT_FOUND\"]\n",
    "    return result\n",
    "\n",
    "\n",
    "def brave_search(query, num=10):\n",
    "    url = \"https://api.search.brave.com/res/v1/web/search\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"X-Subscription-Token\": BRAVE_API_KEY\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"count\": num\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        res = requests.get(url, headers=headers, params=params, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "\n",
    "        web_results = data.get(\"web\", {}).get(\"results\", [])\n",
    "        if not web_results:\n",
    "            print(f\"No results for: {query}\")\n",
    "            return []\n",
    "\n",
    "        return [item.get(\"url\", \"\") for item in web_results if \"url\" in item]\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"Brave API HTTP error for '{query}': {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Brave API general error for '{query}': {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63879f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"us_cities.csv\")\n",
    "\n",
    "output_file = \"verified_city_utilities.csv\"\n",
    "verified_set = set()\n",
    "if os.path.exists(output_file):\n",
    "    try:\n",
    "        verified_df = pd.read_csv(output_file, usecols=[0, 1], header=0, on_bad_lines=\"skip\")\n",
    "        verified_set = set(zip(\n",
    "            verified_df[\"city\"].str.lower().str.strip(),\n",
    "            verified_df[\"state\"].str.lower().str.strip()\n",
    "        ))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error loading verified file: {e}\")\n",
    "        verified_set = set()\n",
    "\n",
    "print(f\"{len(verified_set)} cities already verified. Skipping those.\")\n",
    "write_header = not os.path.exists(output_file) or os.stat(output_file).st_size == 0\n",
    "\n",
    "with open(output_file, mode='a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"city\", \"state\", \"official_site\", \"utility_sites\"],\n",
    "        quoting=csv.QUOTE_MINIMAL\n",
    "    )\n",
    "\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        city = row[\"CITY\"].strip()\n",
    "        state = row[\"STATE_NAME\"].strip()\n",
    "        key = (city.lower(), state.lower())\n",
    "\n",
    "        if key in verified_set:\n",
    "            print(f\"⏭️ Skipping already verified: {city}, {state}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Searching: {city}, {state}\")\n",
    "        try:\n",
    "            info = extract_links(city, state)\n",
    "            query_count += 2\n",
    "            writer.writerow({\n",
    "                \"city\": info[\"city\"],\n",
    "                \"state\": info[\"state\"],\n",
    "                \"official_site\": info[\"official_site\"],\n",
    "                \"utility_sites\": \"; \".join(info[\"utility_sites\"])\n",
    "            })\n",
    "            f.flush()\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {city}, {state}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
